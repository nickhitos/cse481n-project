[{"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-religion1", "p_value": 0.0532, "effect_size": 0.2508514185263073}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-religion1b", "p_value": 0.88118, "effect_size": -0.1836322679864134}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-religion2", "p_value": 9e-05, "effect_size": 0.5773150380265112}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-religion2b", "p_value": 0.20181, "effect_size": 0.1297164562579061}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-angry_black_woman_stereotype", "p_value": 1e-05, "effect_size": 0.7196010406653188}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-angry_black_woman_stereotype_b", "p_value": 0.00448, "effect_size": 0.5132204627404017}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat3", "p_value": 1e-05, "effect_size": 0.8869261264716514}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat3b", "p_value": 0.9833, "effect_size": -0.21530983344046367}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat4", "p_value": 1e-05, "effect_size": 0.8191217449959477}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat5", "p_value": 1e-05, "effect_size": 0.8592970209946171}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat5b", "p_value": 0.39624, "effect_size": 0.026455983996661075}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat6", "p_value": 0.00046, "effect_size": 0.573930128072989}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat6b", "p_value": 0.65729, "effect_size": -0.06410165473785409}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat7", "p_value": 0.83899, "effect_size": -0.16669836367265253}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat7b", "p_value": 0.0002, "effect_size": 0.589210687883104}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat8", "p_value": 0.15846, "effect_size": 0.19023137259850162}, {"experiment_id": "seat_m-INLPAlbertModel_c-albert-base-v2_t-gender", "test": "sent-weat8b", "p_value": 0.0018, "effect_size": 0.5495712270185505}]