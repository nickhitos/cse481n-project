[{"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-religion1", "p_value": 3e-05, "effect_size": 0.6322986259171638}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-religion1b", "p_value": 0.64864, "effect_size": -0.05967622368888177}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-religion2", "p_value": 1e-05, "effect_size": 1.0607551147529009}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-religion2b", "p_value": 0.74727, "effect_size": -0.10451958379515729}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-angry_black_woman_stereotype", "p_value": 0.01087, "effect_size": 0.2949477844895418}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-angry_black_woman_stereotype_b", "p_value": 0.00168, "effect_size": 0.5646865345190585}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat3", "p_value": 1e-05, "effect_size": 0.7985896611355132}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat3b", "p_value": 0.00018, "effect_size": 0.3695515749045623}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat4", "p_value": 1e-05, "effect_size": 0.9764714727442574}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat5", "p_value": 1e-05, "effect_size": 1.0390379583557567}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat5b", "p_value": 3e-05, "effect_size": 0.4318506767386457}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat6", "p_value": 1e-05, "effect_size": 0.8192936798504975}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat6b", "p_value": 0.46942, "effect_size": 0.01167391032547207}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat7", "p_value": 0.99983, "effect_size": -0.593585895612343}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat7b", "p_value": 0.52672, "effect_size": -0.011511657644168385}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat8", "p_value": 0.00149, "effect_size": 0.5484930994270956}, {"experiment_id": "seat_m-INLPBertModel_c-bert-base-uncased_t-race", "test": "sent-weat8b", "p_value": 0.00643, "effect_size": 0.4664868669172719}]